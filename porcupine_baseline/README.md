This implementation is based on the open source WWD porcupine. It represented a strong baseline in my work

- To run streaming inference, simply run python file `stream_porcupine.py`.
- You can manually adjust number of used threads, threshold and the window size inside script.
