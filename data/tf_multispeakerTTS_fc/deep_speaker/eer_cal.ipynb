{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import brentq\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.metrics import roc_curve\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EER(labels, scores):\n",
    "    \"\"\"\n",
    "    Computes EER (and threshold at which EER occurs) given a list of (gold standard) True/False labels\n",
    "    and the estimated similarity scores by the verification system (larger values indicates more similar)\n",
    "    Sources: https://yangcha.github.io/EER-ROC/ & https://stackoverflow.com/a/49555212/1493011\n",
    "    \"\"\"\n",
    "    fpr, tpr, thresholds = roc_curve(labels, scores, pos_label=True)\n",
    "    eer = brentq(lambda x: 1. - x - interp1d(fpr, tpr)(x), 0., 1.)\n",
    "    thresh = interp1d(fpr, thresholds)(eer)\n",
    "    return eer * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For VCTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_trials(npy_dict, N = 4):\n",
    "    # generate N positive trials and N negative trals\n",
    "    labels = []\n",
    "\n",
    "    scores = []\n",
    "    keys = list(npy_dict.keys())\n",
    "    num_keys = len(keys)\n",
    "    for key in tqdm(keys):\n",
    "        index = keys.index(key)\n",
    "        for sample in npy_dict[key]:\n",
    "            s_index = npy_dict[key].index(sample)\n",
    "            temp_list = npy_dict[key][0:s_index] + npy_dict[key][s_index + 1:] if s_index < len(npy_dict[key]) - 1 else npy_dict[key][0:s_index]\n",
    "            embed1 = np.load(sample)\n",
    "            embed1 = embed1/np.math.sqrt(sum(np.power(embed1,2)))\n",
    "            for i in range(N):\n",
    "                labels.append(True)\n",
    "                compare_index = np.random.randint(0, len(temp_list))\n",
    "                compare_npy = temp_list[compare_index]\n",
    "                embed2 = np.load(compare_npy)\n",
    "                embed2 = embed2/np.math.sqrt(sum(np.power(embed2,2)))\n",
    "                scores.append(embed1.dot(embed2.T))\n",
    "\n",
    "                \n",
    "            for i in range(N):\n",
    "                labels.append(False)\n",
    "                temp_klist = keys[0:index] + keys[index + 1:] if index < num_keys - 1 else keys[0:index]\n",
    "                cmp_key = temp_klist[np.random.randint(0, len(temp_klist))]\n",
    "                cmp_index = np.random.randint(0, len(npy_dict[cmp_key]))\n",
    "                embed2 = np.load(npy_dict[cmp_key][cmp_index])\n",
    "                embed2 = embed2/np.math.sqrt(sum(np.power(embed2,2)))\n",
    "                scores.append(embed1.dot(embed2.T))\n",
    "\n",
    "    assert len(scores) == len(labels)\n",
    "    return labels, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict(npy_list):\n",
    "    npy_dict = dict()\n",
    "    for npy in npy_list:\n",
    "        key = npy.split('/')[-1].split('_')[0].replace('embed-', '')\n",
    "        if key not in npy_dict.keys():\n",
    "            npy_dict[key] = []\n",
    "        npy_dict[key].append(npy)\n",
    "    return npy_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speaker EER of the VCTK training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [25:18<00:00, 15.18s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.0602592097735712"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_dir = '../datasets/vctk/synthesizer/embeds/'\n",
    "\n",
    "pairs = []\n",
    "with open('../datasets/vctk/synthesizer/train.txt') as testfile:\n",
    "    for line in testfile.readlines():\n",
    "        items = line.strip().split('|')\n",
    "        pairs.append((embed_dir + items[2]))\n",
    "npy_dict = get_dict(pairs)\n",
    "labels = [k for k in npy_dict.keys()]\n",
    "\n",
    "labels_tf, scores = generate_trials(npy_dict, N=100)\n",
    "EER(labels_tf, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
